{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0tyra0NWJvI"
   },
   "source": [
    "## MNIST machine learning exercise\n",
    "\n",
    "In this exercise we will compare the performance of three different modeling approaches at predicting handwritten numbers. \n",
    "\n",
    "We use the MNIST data set;\n",
    "\n",
    "![mnist data](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmAFVhDJXFBb"
   },
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "48VnFR9cXFP0"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YI7yVb-VW2zi"
   },
   "source": [
    "## Load data and explore/get to know the data structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST digits dataset. It's originally from UCI machine learning library, but included in SKLearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "M8CjaVlYW2Jx",
    "outputId": "e90a4dd3-3781-477f-b02f-97ac3e75be91"
   },
   "outputs": [],
   "source": [
    "mnist = datasets.load_digits() # sklearn includes this data set .. https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the dataset is stored in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "5pPXrazAfUoL",
    "outputId": "593b0df0-7b98-4c9b-e01d-36930d653723"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note thjat there are 1797 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "rTQ7qNp4ffaW",
    "outputId": "3d267533-ac01-4747-abee-369aae5d3d79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797\n"
     ]
    }
   ],
   "source": [
    "print(len(mnist.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are 8x8 grid of values epresenting the gray level for each pixel (16 levels of grey -- from 0 (black) to 15 (white)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "B0ZaSvLlfva0",
    "outputId": "7735e16a-6f2e-41cd-e4e3-55c1dbd5a89d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze this, we simple turn this into a one dimensional array (so we will x1, x2, ... x63, x64). This has already been done for us, and is stored in the data key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "sjDP19CWfT6S",
    "outputId": "f3643de4-6fc9-4810-d5d5-21fb633970fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "Pi5Fvsd_dry5",
    "outputId": "d61e56b6-99c4-486c-b4fa-523f3cb7f1d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(mnist.target[0])\n",
    "print(mnist.target[1])\n",
    "print(mnist.target[2])\n",
    "print(mnist.target[3])\n",
    "print(mnist.target[4])\n",
    "print(mnist.target[5])\n",
    "print(mnist.target[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use matplotlib to display a sample of these images from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qW162_28WC60",
    "outputId": "c7bf771d-ebd1-4a42-e9e4-719d243b814a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAKp0lEQVR4nO3d34tc9RnH8c+nq9LGHyitLZINGQUJSMFdCQEJSBrbEquYXPQiAYVKIVeK0oJo7/oPSHJRhCXqCqZKG3UVsVpBgxVaaxK3rcnGkoaUbKNdQwn+KDREn17sBKJdu2fOnF/z5P2C4O7ssN9niO+cs7Mz5+uIEIA8vtL2AACqRdRAMkQNJEPUQDJEDSRzQR3f1DZPqY+YXq/X2ForVqxobK2TJ082tpYkLSwsNLZWRHip213Hr7SIevRMT083ttbExERjazX5uCRpx44dja31ZVFz+g0kQ9RAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJFMoatubbL9r+4jtB+oeCkB5y0Zte0zSLyTdIuk6SdtsX1f3YADKKXKkXifpSEQcjYjTkp6StLnesQCUVSTqlZKOn/P5fP+2z7G93fY+2/uqGg7A4Iq89XKpd4L8z7uwImJK0pTEu7SANhU5Us9LWnXO5+OSTtQzDoBhFYn6LUnX2r7a9kWStkp6vt6xAJS17Ol3RJyxfbeklyWNSXo0Ig7WPhmAUgpdzigiXpT0Ys2zAKgArygDkiFqIBmiBpIhaiAZogaSIWogGaIGkmGHjg7bvLm5N8PNzMw0tlaTnnvuuUbX27JlS2NrsUMHcJ4gaiAZogaSIWogGaIGkiFqIBmiBpIhaiAZogaSIWogmSI7dDxqe8H2O00MBGA4RY7U05I21TwHgIosG3VEvC7pXw3MAqACha4mWoTt7ZK2V/X9AJRTWdRsuwN0A89+A8kQNZBMkV9pPSnp95LW2J63/eP6xwJQVpG9tLY1MQiAanD6DSRD1EAyRA0kQ9RAMkQNJEPUQDJEDSRT2Wu/zwcbNmxodL2dO3c2ul5Ge/fubXuExnGkBpIhaiAZogaSIWogGaIGkiFqIBmiBpIhaiAZogaSIWogmSLXKFtl+zXbc7YP2r63icEAlFPktd9nJP00Ig7YvlTSftuvRMShmmcDUEKRbXfei4gD/Y8/kjQnaWXdgwEoZ6B3adnuSZqU9OYSX2PbHaADCkdt+xJJT0u6LyI+/OLX2XYH6IZCz37bvlCLQe+OiGfqHQnAMIo8+21Jj0iai4iH6h8JwDCKHKnXS7pT0kbbs/0/P6h5LgAlFdl25w1JbmAWABXgFWVAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJDPye2lNTEw0ttb09HRja0nS6tWrG10vo9nZ2bZHaBxHaiAZogaSIWogGaIGkiFqIBmiBpIhaiAZogaSIWogmSIXHvyq7T/a/lN/252fNzEYgHKKvEz0P5I2RsTH/UsFv2H7NxHxh5pnA1BCkQsPhqSP+59e2P/DxfqBjip6Mf8x27OSFiS9EhFLbrtje5/tfRXPCGAAhaKOiE8jYkLSuKR1tr+9xH2mImJtRKyteEYAAxjo2e+IOCVpr6RNdQwDYHhFnv2+0vbl/Y+/Jum7kg7XPBeAkoo8+32VpMdtj2nxH4FfRcQL9Y4FoKwiz37/WYt7UgMYAbyiDEiGqIFkiBpIhqiBZIgaSIaogWSIGkiGqIFkRn7bnQ0bNjS2FtvgYBRwpAaSIWogGaIGkiFqIBmiBpIhaiAZogaSIWogGaIGkiFqIJnCUfcv6P+2bS46CHTYIEfqeyXN1TUIgGoU3XZnXNKtknbVOw6AYRU9Uu+QdL+kz77sDuylBXRDkR06bpO0EBH7/9/92EsL6IYiR+r1km63fUzSU5I22n6i1qkAlLZs1BHxYESMR0RP0lZJr0bEHbVPBqAUfk8NJDPQ5YwiYq8Wt7IF0FEcqYFkiBpIhqiBZIgaSIaogWSIGkiGqIFkHBHVf1O7+m/aAb1er9H1ZmZmGlvr+uuvb2ytJk1OTja63uzsbGNrRYSXup0jNZAMUQPJEDWQDFEDyRA1kAxRA8kQNZAMUQPJEDWQDFEDyRS6nFH/SqIfSfpU0hkuAwx01yDXKPtORJysbRIAleD0G0imaNQh6be299vevtQd2HYH6Iaip9/rI+KE7W9KesX24Yh4/dw7RMSUpCkp71svgVFQ6EgdESf6/12Q9KykdXUOBaC8IhvkXWz70rMfS/q+pHfqHgxAOUVOv78l6VnbZ+//y4h4qdapAJS2bNQRcVRSzmvdAAnxKy0gGaIGkiFqIBmiBpIhaiAZogaSIWogmUHeenneO3bsWNr1sm670+Q2OF3BkRpIhqiBZIgaSIaogWSIGkiGqIFkiBpIhqiBZIgaSIaogWQKRW37ctt7bB+2PWf7xroHA1BO0dd+75T0UkT80PZFklbUOBOAISwbte3LJN0k6UeSFBGnJZ2udywAZRU5/b5G0geSHrP9tu1d/et/fw7b7gDdUCTqCyTdIOnhiJiU9ImkB754p4iYioi1bHMLtKtI1POS5iPizf7ne7QYOYAOWjbqiHhf0nHba/o33SzpUK1TASit6LPf90ja3X/m+6iku+obCcAwCkUdEbOS+FkZGAG8ogxIhqiBZIgaSIaogWSIGkiGqIFkiBpIhqiBZBwR1X9Tu/pveh7q9XqNrTUzM9PYWk3u23XFFVc0tpYknTp1qrG1IsJL3c6RGkiGqIFkiBpIhqiBZIgaSIaogWSIGkiGqIFkiBpIZtmoba+xPXvOnw9t39fAbABKWPYaZRHxrqQJSbI9Jukfkp6tdywAZQ16+n2zpL9FxN/rGAbA8IpeIvisrZKeXOoLtrdL2j70RACGUvhI3b/m9+2Sfr3U19l2B+iGQU6/b5F0ICL+WdcwAIY3SNTb9CWn3gC6o1DUtldI+p6kZ+odB8Cwim67829JX695FgAV4BVlQDJEDSRD1EAyRA0kQ9RAMkQNJEPUQDJEDSRT17Y7H0ga9O2Z35B0svJhuiHrY+NxtWd1RFy51BdqiboM2/uyvsMr62PjcXUTp99AMkQNJNOlqKfaHqBGWR8bj6uDOvMzNYBqdOlIDaACRA0k04mobW+y/a7tI7YfaHueKtheZfs123O2D9q+t+2ZqmR7zPbbtl9oe5Yq2b7c9h7bh/t/dze2PdOgWv+Zur9BwF+1eLmkeUlvSdoWEYdaHWxItq+SdFVEHLB9qaT9kraM+uM6y/ZPJK2VdFlE3Nb2PFWx/bik30XErv4VdFdExKmWxxpIF47U6yQdiYijEXFa0lOSNrc809Ai4r2IOND/+CNJc5JWtjtVNWyPS7pV0q62Z6mS7csk3STpEUmKiNOjFrTUjahXSjp+zufzSvI//1m2e5ImJb3Z8ihV2SHpfkmftTxH1a6R9IGkx/o/WuyyfXHbQw2qC1F7idvS/J7N9iWSnpZ0X0R82PY8w7J9m6SFiNjf9iw1uEDSDZIejohJSZ9IGrnneLoQ9bykVed8Pi7pREuzVMr2hVoMendEZLm88npJt9s+psUflTbafqLdkSozL2k+Is6eUe3RYuQjpQtRvyXpWttX95+Y2Crp+ZZnGppta/Fns7mIeKjteaoSEQ9GxHhE9LT4d/VqRNzR8liViIj3JR23vaZ/082SRu6JzUE3yKtcRJyxfbeklyWNSXo0Ig62PFYV1ku6U9JfbM/2b/tZRLzY3kgo4B5Ju/sHmKOS7mp5noG1/istANXqwuk3gAoRNZAMUQPJEDWQDFEDyRA1kAxRA8n8F5DViof/1zfEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in np.random.choice(range(0,len(mnist.images)), 4): # choose 4 at random\n",
    "  plt.imshow(mnist.images[i], cmap='gray')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5WfGTWb3hYd-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.72 s\n",
      "Wall time: 3.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ann = MLPClassifier(hidden_layer_sizes=(60,50,40), solver='adam', max_iter=200)\n",
    "_ = ann.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 3.88 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       1.00      1.00      1.00        35\n",
      "           2       0.97      1.00      0.99        36\n",
      "           3       0.95      0.98      0.96        41\n",
      "           4       0.95      0.97      0.96        38\n",
      "           5       0.97      0.97      0.97        30\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       0.97      0.95      0.96        37\n",
      "           8       0.96      0.93      0.95        29\n",
      "           9       0.94      0.97      0.96        34\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "{'solver': 'adam', 'max_iter': 5000, 'learning_rate_init': 0.001, 'learning_rate': 'constant', 'hidden_layer_sizes': (60, 40, 20), 'alpha': 1, 'activation': 'tanh'}\n",
      "CPU times: total: 6.77 s\n",
      "Wall time: 8min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,),(50,30), (40,20), (60,40, 20), (70,50,40)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.97      1.00      0.99        35\n",
      "           2       1.00      1.00      1.00        36\n",
      "           3       1.00      1.00      1.00        41\n",
      "           4       0.97      1.00      0.99        38\n",
      "           5       0.97      0.97      0.97        30\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       1.00      0.95      0.97        37\n",
      "           8       0.97      1.00      0.98        29\n",
      "           9       0.97      0.97      0.97        34\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 9.35 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "{'activation': 'relu', 'alpha': 0.5, 'hidden_layer_sizes': (70,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.005, 'max_iter': 5000, 'solver': 'adam'}\n",
      "CPU times: total: 5.08 s\n",
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (30,), (50,), (70,), (90,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [.5, .7, 1],\n",
    "    'learning_rate': ['adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.005, 0.01, 0.15],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       1.00      1.00      1.00        35\n",
      "           2       1.00      1.00      1.00        36\n",
      "           3       0.98      1.00      0.99        41\n",
      "           4       0.97      1.00      0.99        38\n",
      "           5       0.94      0.97      0.95        30\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       1.00      0.97      0.99        37\n",
      "           8       1.00      0.93      0.96        29\n",
      "           9       0.94      0.97      0.96        34\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 10.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=DecisionTreeClassifier()\n",
    "dt=dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(y_test, dt.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decision Tree\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Search Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best accuracy score is 0.8420489740611691\n",
      "... with parameters: {'min_samples_split': 6, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0076, 'max_leaf_nodes': 74, 'max_depth': 25, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "80 fits failed out of a total of 2500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\akhil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\akhil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\akhil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\akhil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.76824913 0.71399293 0.75363192 0.72793506 0.71329849 0.75154133\n",
      " 0.48990031 0.72583962 0.77453784 0.57622435 0.72723819 0.78637244\n",
      " 0.7494459  0.72373693 0.75993757 0.72789876 0.72163424 0.72442654\n",
      " 0.78006436 0.82186895 0.45721303 0.83718544 0.71468738 0.75083479\n",
      " 0.71815476 0.75432636 0.77939412 0.72163424 0.72442654 0.76894599\n",
      " 0.76615612 0.78426007 0.78915505 0.73902923 0.67992402 0.75083479\n",
      " 0.76132888 0.7243975  0.71676103 0.76968157 0.71816202 0.71815476\n",
      " 0.73485288 0.72648326 0.77245451 0.75432636 0.78146777 0.74667296\n",
      " 0.76828542 0.75014034 0.71468738        nan 0.76203542 0.71329849\n",
      "        nan 0.77662602 0.46557298        nan 0.41963318 0.75153891\n",
      " 0.53029423 0.78217431 0.54766986 0.76615612 0.78217431 0.76131678\n",
      " 0.75014034 0.75091221        nan 0.79610192 0.72094948 0.7153794\n",
      " 0.73624903 0.73902923 0.76964044 0.77523471 0.74737708 0.72512098\n",
      " 0.79261276 0.70426345 0.72163424 0.72093738 0.72093738 0.78915747\n",
      " 0.77452333 0.79681814 0.73485288 0.81908149 0.70774535 0.72930701\n",
      " 0.78566105 0.71611014 0.78147987 0.31384533 0.7251234  0.70218012\n",
      " 0.73624903 0.74597125        nan 0.78217431 0.72373693 0.83648616\n",
      " 0.70774535 0.75083479 0.75362466 0.72720432 0.71814992 0.79401858\n",
      " 0.71885405 0.54210221 0.71468738 0.72093738 0.71815476 0.7633856\n",
      " 0.70705575 0.73902923 0.71329849 0.1892712  0.80098238 0.78147987\n",
      " 0.70426345 0.71746032 0.73485288 0.75014034 0.76477449 0.80932298\n",
      " 0.64721254 0.74736982 0.34239015 0.73902923 0.78565621 0.76202333\n",
      " 0.70843738 0.72653649 0.75226965 0.77590496 0.53029423 0.70287698\n",
      " 0.76964044 0.78217431 0.78706446 0.81629404 0.79191105 0.75646777\n",
      " 0.74669715 0.74041812 0.78565621 0.80446187 0.70356901 0.44886276\n",
      " 0.76689654 0.57622435 0.75293506 0.71814992 0.70774535 0.72442654\n",
      " 0.78568283 0.71814992 0.8030754  0.72023326 0.19485579 0.78497387\n",
      " 0.79401858 0.73485288 0.78357288 0.61730062 0.78217431 0.79818283\n",
      " 0.79681814 0.76685782 0.71468738 0.8232651  0.71745548 0.73485288\n",
      " 0.1892712  0.80792925 0.74669715 0.80029278 0.78147745 0.76828542\n",
      " 0.69170054 0.1892712  0.70356901 0.79678426 0.77940137 0.7633856\n",
      " 0.75363192 0.71814992 0.70774535 0.31384533 0.71816202 0.72930701\n",
      " 0.70774535 0.72093738 0.7933193  0.72093738 0.72442654 0.77939412\n",
      " 0.76058362 0.71611014 0.7494459  0.72373693 0.8030754  0.34239015\n",
      " 0.71399293 0.74667296 0.76549071 0.80793409 0.7272019  0.77033488\n",
      " 0.72930701 0.19485579 0.78844367 0.74876355 0.71885405 0.73624903\n",
      " 0.60753484 0.73832995 0.80863821 0.7251234  0.79539537 0.72930701\n",
      " 0.71468738 0.7633856  0.78285908 0.7494459         nan 0.71399293\n",
      " 0.76968157 0.72718738 0.72442654 0.81420345 0.78635066 0.34239015\n",
      " 0.40155827 0.53029423 0.76828542 0.76825155 0.72094948 0.74669715\n",
      " 0.81836769 0.71539634 0.8100392  0.71745548 0.73487708        nan\n",
      " 0.72442654 0.78565379 0.77940379        nan 0.75226965 0.34239015\n",
      " 0.71676103 0.19485579 0.72094948 0.76615612 0.74667296 0.72442654\n",
      "        nan 0.75014034 0.70218012 0.77245451 0.72789876 0.79679636\n",
      " 0.76477449 0.73624661 0.78845093 0.70774535 0.81420587 0.70218012\n",
      "        nan 0.8100271  0.78703784 0.31384533 0.74741096 0.72442654\n",
      " 0.31384533 0.75014034 0.71122242 0.54141018 0.76689412 0.80237369\n",
      " 0.79262485 0.78636034 0.31384533 0.82117451 0.67505323 0.79748839\n",
      " 0.71399293 0.71399293 0.74669715 0.72093738 0.72442654 0.71745548\n",
      " 0.76129501 0.53029423 0.78635308 0.81907907 0.76824671 0.74041812\n",
      " 0.75920925 0.78566105 0.79193767 0.75715738 0.71399293 0.72373693\n",
      " 0.8093375  0.72027923 0.76894599 0.75502323 0.77454994 0.77938686\n",
      " 0.75432636 0.74667296 0.80585559 0.79470093 0.76202091 0.69593254\n",
      "        nan 0.70426345 0.79680604 0.75153891 0.76481078 0.70705575\n",
      " 0.71814992 0.75154133 0.73558846 0.79539537 0.75154133 0.53029423\n",
      " 0.74321283 0.7418675  0.72023326 0.76131678 0.74669715 0.75919957\n",
      " 0.79957898 0.74321283 0.71816202 0.75154133 0.76615854 0.70356901\n",
      " 0.70426345 0.31384533 0.1892712  0.71814992 0.76272019 0.75919473\n",
      " 0.75083479 0.72094948 0.78846303 0.71468738 0.76131678 0.794021\n",
      " 0.53029423 0.79053184 0.72442654 0.79330478 0.78915747 0.80724932\n",
      " 0.78496419 0.48990031 0.74736982 0.79748597 0.76893631 0.72373693\n",
      " 0.75710898 0.74249903 0.75500629 0.72442654 0.75293506 0.78218399\n",
      " 0.84065283 0.70566444 0.82532666 0.76688928 0.72512098 0.72163424\n",
      " 0.80444251 0.72163424 0.82048006 0.7633856  0.7153794  0.71122484\n",
      " 0.70356901 0.67853513 0.82465399 0.74041812 0.53029423 0.71815476\n",
      " 0.75641454 0.68963899 0.7153794  0.78915263 0.40155827 0.71746032\n",
      " 0.57622435 0.72442654 0.75993757 0.72093738 0.72650987 0.78636034\n",
      " 0.79817799 0.34239015        nan 0.74667296 0.79194251 0.82256581\n",
      " 0.41963318        nan 0.79540505 0.71746032 0.72373693 0.79957172\n",
      " 0.70566444 0.78146777 0.70705575 0.74876355 0.71329849 0.71468738\n",
      " 0.57274245 0.79122629 0.7251234  0.78843157 0.73624903 0.77245451\n",
      " 0.72930701 0.71748935 0.7933193  0.71401955 0.70566444 0.74321283\n",
      "        nan 0.72373693 0.75014034 0.34239015        nan 0.76689654\n",
      " 0.72442654 0.75293748 0.70287698 0.79263695 0.72093738 0.72023326\n",
      " 0.82184233 0.75224061 0.7251234  0.69170054 0.74532762 0.71745548\n",
      " 0.64721254 0.7494459  0.76131678 0.81767325 0.72789876 0.76689654\n",
      " 0.71746032 0.81697638 0.78147745 0.8002952  0.70774535 0.75641454\n",
      "        nan 0.71814992 0.78358256 0.55324477 0.76203542 0.71816202\n",
      " 0.71468738 0.40155827 0.80446429 0.84204897 0.76616338 0.78706204\n",
      " 0.79610434 0.76131678 0.71815476 0.7501476  0.75993757 0.75432636\n",
      " 0.69035521 0.76825155 0.79820703 0.72442654 0.45721303 0.83159843\n",
      " 0.75640002 0.78217431 0.7251234  0.71816202 0.76202091 0.78496419\n",
      " 0.75432636 0.72648326 0.70705575 0.81420587 0.71329849 0.76894599\n",
      " 0.70287698 0.74669715]\n",
      "  warnings.warn(\n",
      "C:\\Users\\akhil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [0.81176115 0.7722726  0.80758694 0.79157967 0.77279479 0.78427426\n",
      " 0.50399909 0.7907095  0.83403307 0.60611708 0.79140576 0.85473463\n",
      " 0.79645015 0.78793022 0.8133291  0.76444106 0.75643819 0.7585259\n",
      " 0.82620093 0.91405774 0.47651372 0.93893609 0.77401294 0.79436213\n",
      " 0.77679797 0.80428108 0.83681311 0.75643819 0.7585259  0.8173291\n",
      " 0.81367495 0.84342392 0.85577871 0.77244455 0.7145094  0.79436213\n",
      " 0.81767874 0.75104386 0.7546983  0.82550664 0.78253831 0.77679797\n",
      " 0.76983479 0.75400235 0.83194521 0.78897007 0.83907383 0.77975192\n",
      " 0.81733061 0.79279631 0.77401294        nan 0.81941847 0.77279479\n",
      "        nan 0.83681568 0.48869081        nan 0.43510788 0.7950599\n",
      " 0.54314451 0.83211564 0.57080546 0.81367495 0.83211564 0.81663465\n",
      " 0.79279631 0.808979          nan 0.84846755 0.78601673 0.77140258\n",
      " 0.76792144 0.77244455 0.81558845 0.83594612 0.7950593  0.764267\n",
      " 0.85595066 0.76548802 0.75643819 0.77940788 0.77940788 0.85577871\n",
      " 0.82567904 0.86151845 0.76983479 0.89318061 0.7595715  0.79488902\n",
      " 0.84150937 0.75330215 0.82846135 0.31524002 0.75904764 0.76426957\n",
      " 0.76792144 0.77836031        nan 0.83211564 0.78793022 0.94989549\n",
      " 0.7595715  0.79436213 0.79279631 0.76374481 0.75556862 0.86117198\n",
      " 0.77627578 0.56297771 0.77401294 0.77940788 0.77679797 0.81489265\n",
      " 0.76235547 0.77244455 0.77279479 0.19728702 0.87526318 0.83559511\n",
      " 0.76548802 0.77801582 0.76983479 0.79279631 0.81576297 0.88726787\n",
      " 0.674665   0.78427336 0.35716563 0.77244455 0.83890022 0.81907004\n",
      " 0.76617944 0.78983963 0.80915458 0.82428637 0.54297045 0.75870163\n",
      " 0.81558845 0.8315939  0.84951512 0.89265857 0.85316759 0.80984977\n",
      " 0.80532804 0.80184917 0.84620714 0.87282688 0.76357332 0.46572748\n",
      " 0.81733061 0.60611708 0.80758694 0.75556862 0.7595715  0.7585259\n",
      " 0.84360071 0.75556862 0.87630605 0.7546983  0.19485072 0.85316865\n",
      " 0.85351254 0.76983479 0.83855163 0.64456624 0.83211564 0.85246831\n",
      " 0.86151845 0.81750301 0.77401294 0.90640224 0.75522049 0.76983479\n",
      " 0.19728702 0.87091232 0.80532804 0.86795626 0.82915942 0.81733061\n",
      " 0.71433398 0.19728702 0.76357332 0.86290975 0.84272827 0.81593703\n",
      " 0.80758694 0.75556862 0.7595715  0.31524002 0.78253831 0.79488902\n",
      " 0.7595715  0.75609036 0.84429197 0.77940788 0.7585259  0.82811503\n",
      " 0.81106596 0.75330215 0.79697188 0.78793022 0.86865161 0.35716563\n",
      " 0.7722726  0.77975192 0.83072676 0.87682915 0.76409324 0.81628425\n",
      " 0.79488902 0.19485072 0.84255315 0.78375237 0.77627578 0.76792144\n",
      " 0.63117145 0.7693126  0.89300761 0.75904764 0.85473236 0.79488902\n",
      " 0.77401294 0.81350089 0.83211564 0.79645015        nan 0.7722726\n",
      " 0.82550664 0.75539456 0.76235229 0.89335422 0.83455148 0.35716563\n",
      " 0.41857857 0.54314451 0.81733061 0.81889507 0.78601673 0.80532804\n",
      " 0.8905707  0.76078965 0.87926318 0.75522049 0.77696084        nan\n",
      " 0.7585259  0.849513   0.84429606        nan 0.80915458 0.35716563\n",
      " 0.7546983  0.19485072 0.78601673 0.81367495 0.77975192 0.76235229\n",
      "        nan 0.79279631 0.76426957 0.83194521 0.76444106 0.84846755\n",
      " 0.81576297 0.76983479 0.85021168 0.7595715  0.89700761 0.76426957\n",
      "        nan 0.88796201 0.83437757 0.31524002 0.80323154 0.7585259\n",
      " 0.31524002 0.79279631 0.76514005 0.55688637 0.82863874 0.88152511\n",
      " 0.84429197 0.84411897 0.31524002 0.89787763 0.70371923 0.85873508\n",
      " 0.7722726  0.7722726  0.80532804 0.77940788 0.76235229 0.75522049\n",
      " 0.8110655  0.54314451 0.84064025 0.90100927 0.81367495 0.80184917\n",
      " 0.81176115 0.84168313 0.85316865 0.8081114  0.7722726  0.78793022\n",
      " 0.8903977  0.78323154 0.8173291  0.80428108 0.84307746 0.82341817\n",
      " 0.80428108 0.77975192 0.87282688 0.86569206 0.8209843  0.72911825\n",
      "        nan 0.76548802 0.8754386  0.7950599  0.81663465 0.76235547\n",
      " 0.75556862 0.78427426 0.80340909 0.85473236 0.78427426 0.54314451\n",
      " 0.80376252 0.79993234 0.7546983  0.81663465 0.80532804 0.80880372\n",
      " 0.86987006 0.80376252 0.78253831 0.78427426 0.81176115 0.76357332\n",
      " 0.76548802 0.31524002 0.19728702 0.75556862 0.82376812 0.8103697\n",
      " 0.79436213 0.78601673 0.85995384 0.77401294 0.81663465 0.8561229\n",
      " 0.54314451 0.85247103 0.7585259  0.85734257 0.86465115 0.87178265\n",
      " 0.83489961 0.50399909 0.78218716 0.85873508 0.81854709 0.78793022\n",
      " 0.79105718 0.78375207 0.80167072 0.7585259  0.80758694 0.84342347\n",
      " 0.95615817 0.76131154 0.90675037 0.82881235 0.764267   0.75643819\n",
      " 0.86865176 0.75643819 0.91840693 0.81593703 0.77140258 0.7675712\n",
      " 0.76357332 0.71572695 0.90292383 0.80184917 0.54314451 0.77679797\n",
      " 0.80184539 0.71694373 0.77140258 0.85542634 0.41857857 0.77801582\n",
      " 0.60611708 0.7585259  0.8133291  0.77940788 0.75835184 0.84498853\n",
      " 0.86291096 0.35716563        nan 0.77975192 0.86830408 0.89787763\n",
      " 0.43510788        nan 0.86256389 0.77801582 0.78793022 0.863433\n",
      " 0.76131154 0.83907383 0.76235547 0.78375237 0.77279479 0.77401294\n",
      " 0.59481515 0.85612215 0.75904764 0.84707822 0.76792144 0.83194521\n",
      " 0.79488902 0.77923109 0.84916305 0.75069346 0.76131154 0.80376252\n",
      "        nan 0.78793022 0.79279631 0.35716563        nan 0.81733061\n",
      " 0.76235229 0.80758694 0.75870163 0.85977917 0.77940788 0.7546983\n",
      " 0.89352904 0.80758694 0.75904764 0.71433398 0.80862875 0.75522049\n",
      " 0.674665   0.79697188 0.81663465 0.88848223 0.76444106 0.81733061\n",
      " 0.77801582 0.88413335 0.82654861 0.86621561 0.7595715  0.80184539\n",
      "        nan 0.75556862 0.85212472 0.58333053 0.81941847 0.78253831\n",
      " 0.77401294 0.41857857 0.8846566  0.94258917 0.81767707 0.84986325\n",
      " 0.86429924 0.81524335 0.77679797 0.80689129 0.8133291  0.78897007\n",
      " 0.74129958 0.81698097 0.86151845 0.7585259  0.47599168 0.94519832\n",
      " 0.80167072 0.83211564 0.75904764 0.78253831 0.8209843  0.83542135\n",
      " 0.78897007 0.75400235 0.76235547 0.89178976 0.77279479 0.81785083\n",
      " 0.75870163 0.80532804]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,50),  \n",
    "    'min_samples_leaf': np.arange(1,50),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 200), \n",
    "    'max_depth': np.arange(1,60), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(y_test,rand_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decisio Tree random\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        43\n",
      "           1       0.91      0.89      0.90        35\n",
      "           2       0.89      0.92      0.90        36\n",
      "           3       0.83      0.85      0.84        41\n",
      "           4       0.78      0.95      0.86        38\n",
      "           5       0.87      0.90      0.89        30\n",
      "           6       1.00      0.97      0.99        37\n",
      "           7       1.00      0.81      0.90        37\n",
      "           8       0.96      0.79      0.87        29\n",
      "           9       0.81      0.88      0.85        34\n",
      "\n",
      "    accuracy                           0.89       360\n",
      "   macro avg       0.90      0.89      0.89       360\n",
      "weighted avg       0.90      0.89      0.90       360\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 10.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 960 candidates, totalling 4800 fits\n",
      "The best accuracy score is 0.8580574912891986\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 23, 'max_leaf_nodes': 74, 'min_impurity_decrease': 0.004, 'min_samples_leaf': 1, 'min_samples_split': 5}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(5,9),  \n",
    "    'min_samples_leaf': np.arange(1,4),\n",
    "    'min_impurity_decrease': np.arange(0.003, 0.008, 0.001),\n",
    "    'max_leaf_nodes': np.arange(72, 76), \n",
    "    'max_depth': np.arange(22,26), \n",
    "    'criterion': ['entropy'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(y_test,grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decision Tree grid Search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94        43\n",
      "           1       0.97      0.91      0.94        35\n",
      "           2       0.89      0.92      0.90        36\n",
      "           3       0.83      0.85      0.84        41\n",
      "           4       0.92      0.95      0.94        38\n",
      "           5       0.83      0.97      0.89        30\n",
      "           6       1.00      0.97      0.99        37\n",
      "           7       0.91      0.81      0.86        37\n",
      "           8       0.96      0.79      0.87        29\n",
      "           9       0.81      0.88      0.85        34\n",
      "\n",
      "    accuracy                           0.90       360\n",
      "   macro avg       0.91      0.90      0.90       360\n",
      "weighted avg       0.91      0.90      0.90       360\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Based on the accuracy results, the neural network with an accuracy of 0.97 outperforms the Decision Tree Classifier with an accuracy of 0.89 in predicting handwritten digits in the MNIST dataset.\n",
    "\n",
    "#After performing hyperparameter tuning using RandomizedSearchCV and GridSearchCV, the accuracy of the neural network improved to 0.99 and 0.98 respectively, which suggests that hyperparameter tuning significantly improved the performance of the model.\n",
    "\n",
    "#On the other hand, the hyperparameter tuning for the Decision Tree Classifier slightly increased from 0.89 to 0.90\n",
    "\n",
    "#Neural network achieved a significantly higher accuracy than the Decision Tree Classifier, and hyperparameter tuning further improved the performance of the neural network. Therefore, the neural network appears to be a better modeling approach for predicting handwritten digits in the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOig4eSm144+FaPk1GKk187",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "mnist_compete_3_models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b056086e24cb5602cbcb82122035cd3d6ee2ccbf5df29c16e348c108b0f83be3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
